---
output:
  pdf_document: default
  html_document: default
---
# Rpr-Reproduction of Social Inequities in the distribution of COVID-19: An intra-categorical analysis of people with disabilities in the U.S.

Joseph Holler, Department of Geography, Middlebury College, Middlebury VT 05753
Drew An-Pham, Department of Geography, Middlebury College, Middlebury VT 05753 Derrick Burt, Department of Geography, Middlebury College, Middlebury VT 05753
Peter Kedron, School of Geographical Sciences and Urban Planning, Arizona State University, Tempe AZ 85281 

Version 1.0 | Created Jul 7, 2021 | Last Updated August 14, 2021

# Abstract

Chakraborty (2021) investigates the relationships between COVID-19 rates and demographic characteristics of people with disabilities by county in the lower 48 states. The study aims to examine public concern that persons with disabilities (PwDs) face disproportionate challenges due to COVID-19. To investigate this, Chakraborty examines the statistical relationship between confirmed county-level COVID-19 case rates and county-level socio-demographic and disability variables. Specifically, Chakraborty tests county-level bivariate correlations between COVID-19 incidence against the percentage of disability and socio-demographic category, with a separate hypothesis and model for each subcategory within disability, race, ethnicity, age, and biological sex. To control for differences between states and geographic clusters of COVID-19 outbreaks, Chakraborty uses five generalized estimating equation (GEE) models to predict the relationship and significance between COVID-19 incidence and disability subgroups within each socio-demographic category while considering inter-county spatial clusters. Chakraborty (2021) finds significant positive relationships between COVID-19 rates and socially vulnerable demographic categories of race, ethnicity, poverty, age, and biological sex.

This reproduction study is motivated by expanding the potential impact of Chakraborty's study for policy, research, and teaching purposes. Measuring the relationship between COVID-19 incidence and socio-demographic and disability characteristics can provide important information for public health policy-making and resource allocation. A fully reproducible study will increase the accessibility, transparency, and potential impact of Chakraborty's (2021) study by publishing a compendium complete with metadata, data, and code. This will allow other researchers to review, extend, and modify the study and will allow students of geography and spatial epidemiology to learn from the study design and methods.

In this reproduction, we will attempt to identically reproduce all of the results from the original study. This will include the map of county level distribution of COVID-19 incidence rates (Fig. 1), the summary statistics for disability and sociodemographic variables and bivariate correlations with county-level COVID-19 incidence rate (Table 1), and the GEE models for predicting COVID-19 county-level incidence rate (Table 2). A successful reproduction should be able to generate identical results as published by Chakraborty (2021).

The replication study data and code will be made available in a GitHub repository to the greatest extent that licensing and file sizes permit. The repository will be made public at [github.com/HEGSRR/RPr-Chakraborty2021](). To the greatest extent possible, the reproduction will be implemented with (3.7.6) Jupyter Notebooks for implementation on the CyberGISX platform with Python (3.7.6) Jupyter Notebooks.

Chakraborty, J. 2021. Social inequities in the distribution of COVID-19: An intra-categorical analysis of people with disabilities in the U.S. Disability and Health Journal 14:1-5. DOI:[10.1016/j.dhjo.2020.101007]()

### Keywords
COVID-19; Disability; Intersectionality; Race/ethnicity; Poverty; Reproducibility

## Study Design
The reproduction study will try to implement the original study as closely as possible to reproduce the map of county level distribution of COVID-19 incidence rate, the summary statistics and bivariate correlation for disability characteristics and COVID-19 incidence, and the generalized estimating equations.
Our two confirmatory hypotheses are that we will be able to exactly reproduce Chakraborty's results as presented in table 1 and table 2 of Chakraborty (2021). Stated as null hypotheses:

> H1: There is a less than perfect match between Chakraborty's bivariate correlation coefficient for each disability/sociodemographic variable and COVID-19 incidence rate and our bivariate correlation coefficient for each disability/sociodemographic variable and COVID-19 incidence rate.

> H2: There is a less than perfect match between Chakraborty's beta coefficient for the GEE of each disability/sociodemographic variable an statistics and our beta coefficient for the GEE of each disability/sociodemographic variable.

There are multiple models being tested within each of the two hypotheses. That is, H1 and H2 both encompass five models, including one for each dimension of socio-demographics: race, ethnicity, poverty status, age, and biological sex.

### Original study design

The original study is **observational**, with the **exploratory** objective of determining "whether COVID-19 incidence is significantly greater in counties containing higher percentages of socio-demographically disadvantaged [people with disabilities], based on their race, ethnicity, poverty status, age, and biological sex" (Chakraborty 2021).
This exploratory objective is broken down into five implicit hypotheses that each of the demographic characteristics of people with disabilities is associated with higher COVID-19 incidence rates.

The **spatial extent** of the study are the 49 contiguous states in the U.S.
The **spatial scale** of the analysis is at the county level.
Both COVID-19 incidence rates and demographic variables are all measured at the county level.
The **temporal extent** of the COVID-19 data ranges from 1/22/2020 (when John Hopkins began collecting the data) to 8/1/2020 (when the data was retrieved for the original study).
The data on disability and sociodemographic characteristics come from the U.S. Census American Community Survey (ACS) five-year estimates for 2018 (2014-2018).

There is no **randomization** in the original study.

The study was originally conducted using SaTScan software (unspecified version) to implement the spatial scan statistic.
Other software are not specified in the publication; however data files and communication with the author show that spatial analysis and mapping was conducted in ArcGIS and statistics were calculated in SPSS.



```{r setup, message = FALSE, include = FALSE}
# list of required packages
# we could probably be listing them all here, making the previous block redundant.
packages = c("tidycensus", "tidyverse", "downloader", "haven", "dplyr", "sf", "classInt", "readr", "ggplot2", "here", "s2", "pastecs", "tmap", "SpatialEpi", "svDialogs", "geepack")

# load and install required packages
package.check <- lapply(
  packages,
  FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
      install.packages(x, dependencies = TRUE, quietly=TRUE)
      library(x, character.only = TRUE)
    }
  }
)

# save the R processing environment 
writeLines(capture.output(sessionInfo()),here("procedure","environment","r_environment.txt"))
```

## Query American Communtity Survey Data
This will require an API key for the census, which can be acquired easily here: [api.census.gov/data/key_signup.html](https://api.census.gov/data/key_signup.html)
This query can take some time to run...

```{r Load ACS Data, message = FALSE, eval = FALSE}
# get API Key
# we could store this in the raw/private or scratch folder and load if the
# researcher has already entered it once
census_api_key(dlgInput("Enter a Census API Key", 
  Sys.getenv("CENSUS_API_KEY"))$res,
  overwrite = TRUE)

# Query disability demographic data with geographic boundaries
acs <- get_acs(geography = "county",
  table = "S1810",
  year = 2018,
  output = "wide",
  cache_table = TRUE,
  geometry = TRUE,
  keep_geo_vars = TRUE) 

# Query poverty and disability data
acs_pov <- get_acs(geography = "county",
  table = "C18130",
  year = 2018,
  output = "wide",
  cache_table = TRUE
)

# Remove Alaska, Hawaii & Puerto Rico
acs <- filter(acs, !STATEFP %in% c("02", "15", "72"))

# Join poverty data to disability data
acs <- left_join(acs, acs_pov, by = "GEOID")
```

## Save raw data

Optionally, you may save the raw data to data/raw/public/acs.gpkg

```{r save ACS data, message = F, eval = FALSE}
# Save downloaded acs data to acs.gpkg
write_sf(acs, here("data", "raw", "public", "acs.gpkg"))
```

## Load raw data

Optionally, you may load the raw data and begin processing here

```{r load ACS data, message = F}
acs <- read_sf(here("data", "raw", "public", "acs.gpkg"))
```

## Preprocess ACS data

Calculate percentages for each sub-category of disability and remove raw census data from the data frame

```{r Preprocess ACS data, message = FALSE}
# calculate percentages
acs_derived <- mutate(acs,
  dis_pct = S1810_C02_001E / S1810_C01_001E * 100,
  white_pct = S1810_C02_004E / S1810_C01_001E * 100,
  black_pct = S1810_C02_005E / S1810_C01_001E * 100,
  native_pct = S1810_C02_006E / S1810_C01_001E * 100,
  asian_pct = S1810_C02_007E / S1810_C01_001E * 100,
  other_pct = 
    (S1810_C02_008E + S1810_C02_009E + S1810_C02_010E)/S1810_C01_001E *100,
  non_hisp_white_pct = S1810_C02_011E / S1810_C01_001E * 100,
  hisp_pct = S1810_C02_012E / S1810_C01_001E * 100,
  non_hisp_non_white_pct = 
    (S1810_C02_001E - S1810_C02_012E - S1810_C02_011E) / S1810_C01_001E * 100,
  bpov_pct = (C18130_004E + C18130_011E + C18130_018E) / C18130_001E * 100, 
  apov_pct = (C18130_005E + C18130_012E + C18130_019E) / C18130_001E * 100,
  pct_5_17 = S1810_C02_014E / S1810_C01_001E * 100,
  pct_18_34 = S1810_C02_015E / S1810_C01_001E * 100,
  pct_35_64 = S1810_C02_016E / S1810_C01_001E * 100,
  pct_65_74 = S1810_C02_017E / S1810_C01_001E * 100,
  pct_75 = S1810_C02_018E / S1810_C01_001E * 100,
  male_pct = S1810_C02_002E / S1810_C01_001E * 100,
  female_pct = S1810_C02_003E / S1810_C01_001E * 100
) 

# select only relevant geographic identifiers and derived percentages
# and transform to USA Contiguous Albers Equal Area Conic projection
acs_derived <- acs_derived %>% 
  select(
    geoid = GEOID,
    statefp = STATEFP,
    county = NAME.x,
    county_st = NAME,
    contains("pct")
  ) %>% 
  st_transform(5070)
```

## Load COVID-19 data
This data has been provided directly with the research compendium because it is no longer available online in the state in which it was downloaded on August 1, 2020.
The data was provided by the original author, Jayajit Chakraborty.

```{r load covid data}
covid <- read_sf(here("data", "raw", "public","covidcase080120.gpkg"))
covid <- select(covid,
  fips = FIPS,
  pop = POP_ESTIMA,
  cases = Confirmed,
  x=X, y=Y)
covid$covid_rate <- covid$cases / covid$pop * 100000
covid_table <- st_drop_geometry(covid)

# It might be wise to calculate our own X and Y using centroids
```

### Join COVID data to ACS data

```{r join data and reorder columns}
# Join poverty data to acs data
covid_rate_table <- select(covid_table, fips, covid_rate)
acs_covid <- left_join(acs_derived, covid_rate_table, by=c("geoid"="fips"))

# move covid_rate prior to percentages
acs_covid <- select(acs_covid, geoid, statefp, county, county_st, covid_rate,
  everything())
```

## Map Covid Rates

```{r map covid rates}

# This is not a working correct map. Need to map 5
# quintile classes of covid_rate to mach figure 1

tm_shape(acs_covid) +
  tm_polygons("covid_rate", 
    title="COVID-19 Cases per 100,000",
    style="quantile",
    border.alpha = .2,
    lwd = 0.2,
    palette="YlOrBr"
  )

```

## Map Disability Rates

```{r map disability rates}

tm_shape(acs_covid) +
  tm_polygons("dis_pct", 
    title="Percent with Disability",
    style="quantile",
    border.alpha = .2,
    lwd = 0.2,
    palette="YlOrBr"
  )

```

## Missing Data

All descriptive statistics match the original results with the exception of
the minimum people with disability below poverty and people with disability
above poverty percentages. There is one county with missing people with 
disability poverty data, for with Chakraborty may have replaced missing data
with zero-- a reasonable decision if data was suppressed due to small numbers.

```{r missing data}

# county with missing data
filter(acs_covid, is.na(bpov_pct))

# replace NA with 0 for missing data
acs_covid[is.na(acs_covid$bpov_pct), ]$bpov_pct <- 0
acs_covid[is.na(acs_covid$apov_pct), ]$apov_pct <- 0

```

## Descriptive Statistics

```{r descriptive statistics}
acs_covid_stats <- acs_covid %>% 
  st_drop_geometry() %>% 
  select(is.numeric) %>% 
  stat.desc(norm=TRUE) %>% 
  round(2) %>% 
  t() %>% as.data.frame() %>% 
  select(min, max, mean, SD = std.dev, ShapiroWilk = normtest.W, p = normtest.p)

acs_covid_stats
```
p > 0.005 = not a normal distribution, p = how sig. the ShapiroWilk test is
ShapiroWilk being a test of normality, gives a # that then needs to be assessed for sig.


## Calculate Pearson's R Correlation Coefficients

These results are identical in direction and significance to Chakraborty's,
but differ slightly in magnitude.

```{r pearsons correlation}
df = sum(!is.na(acs_covid$dis_pct)) - 2

pearsons_r <- acs_covid %>%
  select(where(is.numeric)) %>% 
  st_drop_geometry() %>% 
  cor(method="pearson", use="pairwise.complete.obs") %>% 
  as.data.frame() %>%
  select(r = covid_rate) %>% 
  mutate(
    t = abs(r) / sqrt((1 - r^2)/(df) ),
    p = pt(t, df, lower.tail = FALSE)
    ) %>% 
  round(3) %>%
  rownames_to_column("variable") %>% 
  filter(variable != "covid_rate")

pearsons_r
# this estimation of t gives similar, but not identical, result to corr.test
# consider trying the rstatix package for this!
```
r = -1 to 1, same as below 1= perf pos corralation, -1= perf negative, 0 = no correlation, P = sig. 

## Calculate Spearman's Rho Correlation Coefficients

Try a non-parametric correlation test because variables do not have
normal distributions (see Shapiro-Wilk test results above).
The direction of several of the variables changes with the non-parametric
test.

```{r spearmans correlation}
df = sum(!is.na(acs_covid$dis_pct)) - 2

spearmans_rho <- acs_covid %>%
  select(where(is.numeric)) %>% 
  st_drop_geometry() %>% 
  cor(method="spearman", use="pairwise.complete.obs") %>% 
  as.data.frame() %>%
  select(rho = covid_rate) %>% 
  mutate(
    t = abs(rho) / sqrt((1 - rho^2)/(df) ),
    p = pt(t, df, lower.tail = FALSE)
    ) %>% 
  round(3) %>%
  rownames_to_column("variable") %>% 
  filter(variable != "covid_rate")

spearmans_rho
```
P = sig. rho = -1 to 1, -1= perf neg correlation, 1= perf pos correlation, 0 = no correlation

## Kulldorf Spatial Scan Cluster Detection

Note that the statistic is a Monte Carlo simulation with 999 iterations.
Therefore, if you wish to exactly reproduce the same results as our reproduction
attempt, please **do not run this section**.
Instead, load the scan results below.
This code block can take more than 10-20 minutes to run.

```{r SpatialEpi Kulldorff spatial scan, eval = FALSE}
covid_geo <- covid_table %>% 
  select(x, y) %>%
  latlong2grid()
# latlong2grid approximates an equidistant grid measured in kilometers
# need to look more into the methods of this, but it surely is not as good
# as a geodesic calculation. SaTScan uses spherical or ellipsoidal distance

# calculate expected cases with one strata
expected.cases <- expected(covid_table$pop, covid_table$cases , 1)

# Kulldorff spatial scan statistic
covid_kulldorff <- kulldorff(geo=covid_geo,
                             cases=covid_table$cases,
                             population=covid_table$pop,
                             expected.cases=expected.cases,
                             pop.upper.bound=0.5,
                             n.simulations=999,
                             alpha.level=0.05,
                             plot=TRUE
)

rm(covid_table, covid_geo, expected.cases)
```

## Save scan results

```{r save spatial scan results, eval = FALSE}
saveRDS(covid_kulldorff,
  file=here("data","derived","public","covid_kulldorff.RDS"))
```

## Load scan results

```{r load spatial scan results}
covid_kulldorff <- readRDS(
  here("data","derived","public","covid_kulldorff.RDS")
  )
```


## Summarize spatial scan clusters by county

Summarize the results of the Kulldorff spatial scan cluster detection by county
Code each county `0` if it is not in a cluster and `1` if it is in a cluster.

```{r summarize Kulldorff results}
# Get counties in most significant cluster
# Note that the ID numbers are row numbers
clusters <- covid_kulldorff$most.likely.cluster$location.IDs.included

# Get list of secondary clusters
secondary <- covid_kulldorff$secondary.clusters

# Get counties from each secondary cluster
for (i in secondary) {
  clusters <- c(clusters, i$location.IDs.included)
}

# Create blank column "cluster" with 0's
covid$cluster <- 0

# Change cluster to 1 for any county identified in any cluster
covid[clusters, ]$cluster <- 1

# Calculate and Classify Local Relative Risk
# cut() classifies rr_loc from 1 to 6
# * cluster forces counties outside of clusters to be assigned to class 0
covid <- covid %>% 
  mutate( 
    rr_loc = 
      (cases / pop) / ((sum(covid$cases) - cases) / (sum(covid$pop) - pop)),
    rr_class = 
      (cut(rr_loc, c(-Inf,1,2,3,4,5,Inf), labels=FALSE) - 1) * cluster + 1
  ) %>% 
  st_transform(5070)
```

### How did the classification work?

```{r classification results}
# Count frequency of each class of COVID risk
cat("Classes of risk and frequency of counties",
  format(covid %>% st_drop_geometry %>% count(rr_class)), sep="\n")

cat("\n",
    sum(covid$cluster==0 & covid$rr_loc >= 1),
  " counties lie outside of a cluster, but have local relative risk > 1\n\n",
  sum(covid$cluster==1 & covid$rr_loc < 1),
  " counties lie inside of a cluster, but have a local relative risk < 1",
  sep="") 

# There's a relative risk score for both county & cluster (in SatScan)
# This reproduction uses county-based relative risk scores based on
# paragraph 4 of the methods section of the paper and Desjardins et al
```
## Map Relative Risk Scores

Note that relative risk is > 1 only if the county was in a cluster

```{r map relative risk scores}
# Map Relative Risk scores
tm_shape(covid) +
  tm_polygons("rr_class", 
    title="Local Relative Risk",
    border.alpha = .2,
    lwd = 0.2,
    palette="YlOrBr",
    style="cat"
  )
```

## Preprocess data for GEE modelling

```{r preprocess data for GEE model }
covid_clusters <- covid %>% 
  select(fips, cluster, rr_loc, rr_class) %>% 
  st_drop_geometry

# Filter out non-positive COVID rates and missing data
# Create unique State - Relative Risk IDs by combining state code and rr_class
# Sort by the cluster id's (a requirement of the gee function)
gee_data <- left_join(acs_covid, covid_clusters, by = c("geoid"="fips")) %>%
  filter(covid_rate > 0) %>% 
  mutate(id = as.integer(statefp) * 10 + rr_class) %>% 
  arrange(id)

rm(covid_clusters)
```
mutate gives the state # x 10 (so 2 digits are state id) + class as the third digit

## Save preprocessed GEE data inputs

Optionally, you may save the preprocessed to `data/raw/public/gee_data.gpkg`

```{r save preprocessed COVID cluster data, eval = FALSE}
write_sf(gee_data, here("data","derived","public","gee_data.gpkg"))
```

## Load preprocessed GEE input data

Optionally, you may load the preprocessed data from `data/raw/public/gee_data.gpkg`

```{r load preprocessed COVID cluster data, eval = FALSE}
gee_data <- read_sf(here("data","derived","public","gee_data.gpkg"))
```

# Report number of unique clusters

```{r}
cluster_summary <- gee_data %>% 
  st_drop_geometry %>% 
  count(id)
cat(length(cluster_summary$n), "unique clusters\n")
summary(cluster_summary$n)
```
number of unique clusters = # of obs in cluster_summary, max = one cluster w 184 counties, mean = on average each cluster has 22 counties in it

## GEE Models

Generalized Estimating Equation parameters:

"The **‘exchangeable’ correlation matrix** was selected for the results reported here, since this speci-fication yielded the best statistical fit based on the QIC (quasi- likelihood under the independence) model criterion."
(Chakraborty 2021, Methods paragraph 5)

"The **gamma distribution** with **logarithmic link function** was chosen for all GEEs since this model specification provided the lowest QIC value."
(Chakraborty 2021, Methods paragraph 5)

Useful Reference:
https://data.library.virginia.edu/getting-started-with-generalized-estimating-equations/

```{r gee models}

# it would be smarter to iterate over a list of models and their parameters
# currently stuck on how to add GLM model results to a cell of a dataframe
# not the only one:
# https://www.reddit.com/r/rstats/comments/p50mce/coding_a_loop_for_many_linear_regressions/

race_gee <- geeglm(
  covid_rate ~ white_pct + black_pct + native_pct + asian_pct + other_pct, 
  data = gee_data, # data frame
  id = id, # cluster IDs
  family = Gamma(link = "log"),
  corstr = "exchangeable"
)

# Wald and P calculated in summary only; 
# coef() extracts coefficients table from the summary, same as $coefficients 

ethnicity_gee <- geeglm(
  covid_rate ~ non_hisp_white_pct + hisp_pct + non_hisp_non_white_pct,
  data = gee_data, 
  id = id,
  family = Gamma(link = "log"),
  corstr = "exchangeable"
)

pov_gee <- geeglm(
  covid_rate ~ bpov_pct + apov_pct, 
  data = gee_data, 
  id = id, 
  family = Gamma(link = "log"), 
  corstr = "exchangeable",
)

age_gee <- geeglm(
  covid_rate ~ pct_5_17 + pct_18_34 + pct_35_64 + pct_65_74 + pct_75,
  data = gee_data,
  id = id,
  family = Gamma(link = "log"),
  corstr = "exchangeable"
)

sex_gee <- geeglm(
  covid_rate ~ male_pct + female_pct,
  data = gee_data, 
  id = id,
  family = Gamma(link = "log"), 
  corstr = "exchangeable"
)

# summarize model coefficients
coefficient_results <- rbind(coef(summary(race_gee)),
  coef(summary(ethnicity_gee)),
  coef(summary(pov_gee)),
  coef(summary(age_gee)),
  coef(summary(sex_gee))
  ) %>% 
  round(3)

# disambiguate intercepts
coefrows <- rownames(coefficient_results)
coefrows[1] <- "Race Intercept"
coefrows[7] <- "Ethnicity Intercept"
coefrows[11] <- "Poverty Status Intercept"
coefrows[14] <- "Age Intercept"
coefrows[20] <- "Biological Sex Intercept"
rownames(coefficient_results) <- coefrows
coefficient_results

# summarize model QICs
QIC_results <- data.frame(race = QIC(race_gee),
  ethnicity = QIC(ethnicity_gee),
  poverty_status = QIC(pov_gee),
  age = QIC(age_gee),
  biological_sex = QIC(sex_gee)
  ) %>% 
  round(3) %>% 
  t() %>%
  as.data.frame() %>% 
  select(QIC)
QIC_results

```
estimate = + more likely to have covid, - = less likely to have covid, std.err = standard error, estimate is the slope, low = not a huge impact, wald = chi squared its a stats test, pr = prob. want to be at 0 bc we're trying to reject the null hypothesis, accepted if p > 0.05

intercept = baseline covid rate, slope = how much it matters

cluster has rel risk score for each cluster, orig. did risk score for center of the cluster applied to the whole cluster, could still be better by avg the risk score or taking the highest risk score in the cluster, 